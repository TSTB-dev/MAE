/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 main.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 main.py ...
  rank_zero_warn(
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type                 | Params
-----------------------------------------------
0 | model | MaskedAutoencoderViT | 111 M
-----------------------------------------------
111 M     Trainable params
252 K     Non-trainable params
111 M     Total params
447.631   Total estimated model params size (MB)



Sanity Checking DataLoader 0: 100%|██████████████████████| 1/1 [00:01<00:00,  1.30s/it]
/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(

















Epoch 9: 100%|█████████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.154, train_loss_epoch=0.182]




















Epoch 19: 100%|███████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0897, train_loss_epoch=0.107]



















Epoch 29: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0709, train_loss_epoch=0.0741]





















Epoch 39: 100%|███████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s, v_num=kn88, train_loss_step=0.0561, train_loss_epoch=0.058]




















Epoch 49: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.43it/s, v_num=kn88, train_loss_step=0.0535, train_loss_epoch=0.0515]



















Epoch 59: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0451, train_loss_epoch=0.0457]





















Epoch 69: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0436, train_loss_epoch=0.0447]




















Epoch 79: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0397, train_loss_epoch=0.0432]



















Epoch 89: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0399, train_loss_epoch=0.0391]




















Epoch 99: 100%|███████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0371, train_loss_epoch=0.037]



















Epoch 109: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.0341, train_loss_epoch=0.0351]




















Epoch 119: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.034, train_loss_epoch=0.0334]




















Epoch 129: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.43it/s, v_num=kn88, train_loss_step=0.0299, train_loss_epoch=0.0331]




















Epoch 139: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.0299, train_loss_epoch=0.0314]



















Epoch 149: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0312, train_loss_epoch=0.0322]




















Epoch 159: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0305, train_loss_epoch=0.0315]




















Epoch 169: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0324, train_loss_epoch=0.029]




















Epoch 179: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0294, train_loss_epoch=0.028]



















Epoch 189: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s, v_num=kn88, train_loss_step=0.0265, train_loss_epoch=0.0272]



















Epoch 199: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.0272, train_loss_epoch=0.0272]




















Epoch 209: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0241, train_loss_epoch=0.025]




















Epoch 219: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.0252, train_loss_epoch=0.0265]



















Epoch 229: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s, v_num=kn88, train_loss_step=0.0265, train_loss_epoch=0.0246]





















Epoch 239: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.0251, train_loss_epoch=0.0257]




















Epoch 249: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0225, train_loss_epoch=0.0232]




















Epoch 259: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s, v_num=kn88, train_loss_step=0.0211, train_loss_epoch=0.0224]




















Epoch 269: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.43it/s, v_num=kn88, train_loss_step=0.0214, train_loss_epoch=0.0219]




















Epoch 279: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s, v_num=kn88, train_loss_step=0.0212, train_loss_epoch=0.0219]



















Epoch 289: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.42it/s, v_num=kn88, train_loss_step=0.0222, train_loss_epoch=0.0213]




















Epoch 299: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.36it/s, v_num=kn88, train_loss_step=0.0209, train_loss_epoch=0.0205]




















Epoch 309: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0201, train_loss_epoch=0.0201]



















Epoch 319: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0211, train_loss_epoch=0.0201]




















Epoch 329: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0205, train_loss_epoch=0.0205]




















Epoch 339: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0203, train_loss_epoch=0.0195]





















Epoch 349: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0184, train_loss_epoch=0.0196]



















Epoch 359: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0193, train_loss_epoch=0.0184]





















Epoch 369: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s, v_num=kn88, train_loss_step=0.0179, train_loss_epoch=0.0183]




















Epoch 379: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.38it/s, v_num=kn88, train_loss_step=0.0176, train_loss_epoch=0.018]




















Epoch 389: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0179, train_loss_epoch=0.0184]




















Epoch 399: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.38it/s, v_num=kn88, train_loss_step=0.0175, train_loss_epoch=0.0182]




















Epoch 409: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0176, train_loss_epoch=0.0173]





















Epoch 419: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0173, train_loss_epoch=0.0175]



















Epoch 429: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.35it/s, v_num=kn88, train_loss_step=0.0178, train_loss_epoch=0.0169]



















Epoch 439: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.43it/s, v_num=kn88, train_loss_step=0.016, train_loss_epoch=0.0168]




















Epoch 449: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.38it/s, v_num=kn88, train_loss_step=0.0172, train_loss_epoch=0.0174]



















Epoch 459: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.38it/s, v_num=kn88, train_loss_step=0.0172, train_loss_epoch=0.0172]




















Epoch 469: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.37it/s, v_num=kn88, train_loss_step=0.0162, train_loss_epoch=0.0168]




















Epoch 479: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.017, train_loss_epoch=0.0172]



















Epoch 489: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s, v_num=kn88, train_loss_step=0.0163, train_loss_epoch=0.0161]




















Epoch 499: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.39it/s, v_num=kn88, train_loss_step=0.0159, train_loss_epoch=0.0158]


Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.11it/s]

Epoch 499: 100%|█████████████████████████████████████| 5/5 [00:25<00:00,  5.12s/it, v_num=kn88, train_loss_step=0.0159, train_loss_epoch=0.0158]