/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 main.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 main.py ...
  rank_zero_warn(
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type                 | Params
-----------------------------------------------
0 | model | MaskedAutoencoderViT | 111 M
-----------------------------------------------
111 M     Trainable params
252 K     Non-trainable params
111 M     Total params
447.631   Total estimated model params size (MB)



Sanity Checking DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]
Epoch 0:   0%|                                                                                                            | 0/5 [00:00<?, ?it/s]
/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.














Epoch 9: 100%|█████████████████████████████████████████| 5/5 [00:02<00:00,  1.75it/s, v_num=3wz9, train_loss_step=0.204, train_loss_epoch=0.540]
















Epoch 19: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.72it/s, v_num=3wz9, train_loss_step=0.0321, train_loss_epoch=0.0358]















Epoch 29: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.0249, train_loss_epoch=0.0256]

















Epoch 39: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.72it/s, v_num=3wz9, train_loss_step=0.0208, train_loss_epoch=0.0217]


















Epoch 49: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.75it/s, v_num=3wz9, train_loss_step=0.0197, train_loss_epoch=0.0199]
















Epoch 59: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.0181, train_loss_epoch=0.0188]

















Epoch 69: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.71it/s, v_num=3wz9, train_loss_step=0.0165, train_loss_epoch=0.0172]

















Epoch 79: 100%|███████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.018, train_loss_epoch=0.0159]
















Epoch 89: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.0168, train_loss_epoch=0.0162]


















Epoch 99: 100%|███████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.015, train_loss_epoch=0.0146]















Epoch 109: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.72it/s, v_num=3wz9, train_loss_step=0.014, train_loss_epoch=0.0145]


















Epoch 119: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.0139, train_loss_epoch=0.0134]
















Epoch 129: 100%|██████████████████████████████████████| 5/5 [00:02<00:00,  1.72it/s, v_num=3wz9, train_loss_step=0.0125, train_loss_epoch=0.013]


















Epoch 139: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.0129, train_loss_epoch=0.0127]
















Epoch 149: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.0116, train_loss_epoch=0.0122]

















Epoch 159: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.0117, train_loss_epoch=0.0122]

















Epoch 169: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.73it/s, v_num=3wz9, train_loss_step=0.0118, train_loss_epoch=0.0116]

















Epoch 179: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.0107, train_loss_epoch=0.0107]
















Epoch 189: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.65it/s, v_num=3wz9, train_loss_step=0.0101, train_loss_epoch=0.0107]
















Epoch 199: 100%|█████████████████████████████████████| 5/5 [00:02<00:00,  1.71it/s, v_num=3wz9, train_loss_step=0.0102, train_loss_epoch=0.0103]

















Epoch 209: 100%|████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.00944, train_loss_epoch=0.0106]
















Epoch 219: 100%|████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.0102, train_loss_epoch=0.00974]
















Epoch 229: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.72it/s, v_num=3wz9, train_loss_step=0.00855, train_loss_epoch=0.00989]
















Epoch 239: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00878, train_loss_epoch=0.00929]
















Epoch 249: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.00936, train_loss_epoch=0.00907]

















Epoch 259: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.00837, train_loss_epoch=0.00913]

















Epoch 269: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s, v_num=3wz9, train_loss_step=0.00838, train_loss_epoch=0.00871]

















Epoch 279: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.00841, train_loss_epoch=0.00862]


















Epoch 289: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.00872, train_loss_epoch=0.00844]
















Epoch 299: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00763, train_loss_epoch=0.00832]
















Epoch 309: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00797, train_loss_epoch=0.00804]


















Epoch 319: 100%|███████████████████████████████████| 5/5 [00:03<00:00,  1.63it/s, v_num=3wz9, train_loss_step=0.00797, train_loss_epoch=0.00744]
















Epoch 329: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.00737, train_loss_epoch=0.00733]

















Epoch 339: 100%|████████████████████████████████████| 5/5 [00:03<00:00,  1.66it/s, v_num=3wz9, train_loss_step=0.0078, train_loss_epoch=0.00716]

















Epoch 349: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.00705, train_loss_epoch=0.00713]
















Epoch 359: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.71it/s, v_num=3wz9, train_loss_step=0.00662, train_loss_epoch=0.00708]


















Epoch 369: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.00744, train_loss_epoch=0.00733]

















Epoch 379: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.00662, train_loss_epoch=0.00719]
















Epoch 389: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00692, train_loss_epoch=0.00698]
















Epoch 399: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00649, train_loss_epoch=0.00665]

















Epoch 409: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.00662, train_loss_epoch=0.00641]


















Epoch 419: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00617, train_loss_epoch=0.00673]
















Epoch 429: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s, v_num=3wz9, train_loss_step=0.00698, train_loss_epoch=0.00695]

















Epoch 439: 100%|████████████████████████████████████| 5/5 [00:02<00:00,  1.71it/s, v_num=3wz9, train_loss_step=0.0056, train_loss_epoch=0.00654]
















Epoch 449: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.00588, train_loss_epoch=0.00601]

















Epoch 459: 100%|███████████████████████████████████| 5/5 [00:03<00:00,  1.64it/s, v_num=3wz9, train_loss_step=0.00645, train_loss_epoch=0.00607]


















Epoch 469: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.71it/s, v_num=3wz9, train_loss_step=0.00604, train_loss_epoch=0.00579]
















Epoch 479: 100%|████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s, v_num=3wz9, train_loss_step=0.0061, train_loss_epoch=0.00584]
















Epoch 489: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.71it/s, v_num=3wz9, train_loss_step=0.00635, train_loss_epoch=0.00602]

















Epoch 499: 100%|███████████████████████████████████| 5/5 [00:02<00:00,  1.70it/s, v_num=3wz9, train_loss_step=0.00579, train_loss_epoch=0.00566]



Epoch 499: 100%|███████████████████████████████████| 5/5 [00:30<00:00,  6.03s/it, v_num=3wz9, train_loss_step=0.00579, train_loss_epoch=0.00594]
`Trainer.fit` stopped: `max_epochs=500` reached.