/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 main.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 main.py ...
  rank_zero_warn(
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type                 | Params
-----------------------------------------------
0 | model | MaskedAutoencoderViT | 111 M
-----------------------------------------------
111 M     Trainable params
252 K     Non-trainable params
111 M     Total params
447.631   Total estimated model params size (MB)


Sanity Checking DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.53it/s]
Epoch 0:   0%|                                                                                                            | 0/5 [00:00<?, ?it/s]
/media/dl/hutodama/MAE/env/mae/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

















Epoch 9: 100%|█████████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.191, train_loss_epoch=0.341]





















Epoch 19: 100%|████████████████████████████████████████| 5/5 [00:03<00:00,  1.28it/s, v_num=1oij, train_loss_step=0.110, train_loss_epoch=0.114]



















Epoch 29: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.33it/s, v_num=1oij, train_loss_step=0.0995, train_loss_epoch=0.0992]





















Epoch 39: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0939, train_loss_epoch=0.0913]






















Epoch 49: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0895, train_loss_epoch=0.0833]





















Epoch 59: 100%|███████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.082, train_loss_epoch=0.0824]





















Epoch 69: 100%|████████████████████████████████████████| 5/5 [00:03<00:00,  1.34it/s, v_num=1oij, train_loss_step=0.081, train_loss_epoch=0.079]





















Epoch 79: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.32it/s, v_num=1oij, train_loss_step=0.0767, train_loss_epoch=0.0757]





















Epoch 89: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.28it/s, v_num=1oij, train_loss_step=0.0701, train_loss_epoch=0.0723]





















Epoch 99: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0722, train_loss_epoch=0.0723]





















Epoch 109: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0702, train_loss_epoch=0.0686]






















Epoch 119: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0708, train_loss_epoch=0.0683]





















Epoch 129: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0601, train_loss_epoch=0.0648]





















Epoch 139: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0625, train_loss_epoch=0.063]




















Epoch 149: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.065, train_loss_epoch=0.0608]





















Epoch 159: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0639, train_loss_epoch=0.061]



















Epoch 169: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.32it/s, v_num=1oij, train_loss_step=0.0585, train_loss_epoch=0.0577]






















Epoch 179: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.32it/s, v_num=1oij, train_loss_step=0.0571, train_loss_epoch=0.0547]




















Epoch 189: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0516, train_loss_epoch=0.0521]





















Epoch 199: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0517, train_loss_epoch=0.0512]




















Epoch 209: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0494, train_loss_epoch=0.0488]






















Epoch 219: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0489, train_loss_epoch=0.0482]






















Epoch 229: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0461, train_loss_epoch=0.0457]






















Epoch 239: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0444, train_loss_epoch=0.0449]




















Epoch 249: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.27it/s, v_num=1oij, train_loss_step=0.041, train_loss_epoch=0.0413]





















Epoch 259: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.32it/s, v_num=1oij, train_loss_step=0.0395, train_loss_epoch=0.0412]





















Epoch 269: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0366, train_loss_epoch=0.0395]





















Epoch 279: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.32it/s, v_num=1oij, train_loss_step=0.0347, train_loss_epoch=0.0361]




















Epoch 289: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0352, train_loss_epoch=0.0349]






















Epoch 299: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.33it/s, v_num=1oij, train_loss_step=0.0341, train_loss_epoch=0.0335]



















Epoch 309: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0298, train_loss_epoch=0.0333]






















Epoch 319: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.33it/s, v_num=1oij, train_loss_step=0.0329, train_loss_epoch=0.0314]





















Epoch 329: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0289, train_loss_epoch=0.0307]





















Epoch 339: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0269, train_loss_epoch=0.0288]






















Epoch 349: 100%|██████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.026, train_loss_epoch=0.0263]



















Epoch 359: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0266, train_loss_epoch=0.0271]





















Epoch 369: 100%|███████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.026, train_loss_epoch=0.026]




















Epoch 379: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0236, train_loss_epoch=0.0248]




















Epoch 389: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0227, train_loss_epoch=0.0237]





















Epoch 399: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.27it/s, v_num=1oij, train_loss_step=0.0242, train_loss_epoch=0.0226]






















Epoch 409: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.28it/s, v_num=1oij, train_loss_step=0.0216, train_loss_epoch=0.0222]





















Epoch 419: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0227, train_loss_epoch=0.0223]





















Epoch 429: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0216, train_loss_epoch=0.0214]



















Epoch 439: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0194, train_loss_epoch=0.0206]





















Epoch 449: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.29it/s, v_num=1oij, train_loss_step=0.0189, train_loss_epoch=0.0206]





















Epoch 459: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0198, train_loss_epoch=0.0195]






















Epoch 469: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0194, train_loss_epoch=0.0189]





















Epoch 479: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0179, train_loss_epoch=0.0184]






















Epoch 489: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.30it/s, v_num=1oij, train_loss_step=0.0182, train_loss_epoch=0.0183]





















Epoch 499: 100%|█████████████████████████████████████| 5/5 [00:03<00:00,  1.31it/s, v_num=1oij, train_loss_step=0.0175, train_loss_epoch=0.0177]


Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 35.73it/s]

Epoch 499: 100%|█████████████████████████████████████| 5/5 [00:25<00:00,  5.18s/it, v_num=1oij, train_loss_step=0.0175, train_loss_epoch=0.0179]